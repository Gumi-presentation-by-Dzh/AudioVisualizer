<!DOCTYPE html>
<html>

	<head>
		<meta charset="utf-8" />
		<meta name="renderer" content="webkit">
		<meta name="viewport" content="width=device-width,initial-scale=1.0,user-scalable=no">
		<meta name="Keywords" content="音乐可视化,webAudio,music,音乐,HTML5,canvas,CSS3,自适应">
		<meta name="Description" content="利用HTML5 webAudio API 和canvas API以及CSS3制作音乐播放可视化效果">
		<meta name="Author" content="Doving & XQ">
		<title>HTML5 Audio API Demo</title>
		<style type="text/css">
			html,
			body {
				margin: 0;
				padding: 0;
				font-family: arial, "Microsoft YaHei";
				font-size: 14px;
				background-color: #272822;
				color: #FEFEFE;
			}
			
			div.msg {
				position: fixed;
				left: 5px;
				bottom: 5px;
				/*width: 500px;
				height: 300px;*/
				/*background-color: #87CEEB;*/
			}
			
			#info,#uploader{    
				padding: 0;
    			margin: 1px;
    		}
			
			#drawCanvas{
				/*border: 1px solid blue;*/
			}
		</style>
	</head>

	<body>
		<div id="container">
			<div class="msg">
				<p id="info">Open Mp3 file:</p>
				<input type="file" id="uploader" />
			</div>
			<canvas id="drawCanvas" width="" height=""></canvas>
		</div>

		<script type="text/javascript">
		"use strict"
		window.innerHeight
		/*
		 * I learned this HTML5 Audio API from liuwayong's blog:
		 * http://www.cnblogs.com/Wayou/p/html5_audio_api_visualizer.html
		 * I use some codes of his demo, and creat a new visualize style.
		 * For more info you can visit my blog: 
		 * or contact me: qieguo.chow@gmail.com
		 * 核心流程：
		 * 1, new FileReader().readAsArrayBuffer(file) >>
		 * 2, new AudioContext().decodeAudioData(readResult, function(buffer), function(err))
		 * 3, buff = audioContext.createBufferSource(): for play, ana = audioContext.createAnalyser() for analysis
		 * 4, buff.connect(ana), ana.connect(audioContext.destination), buff.buffer = buffer, buff.start(0); for output
		 * 5, use ana to do analysis.
		 */
		window.onload = function() {
			setWin();
			//浏览器加载时初始化MV对象
			new MV().init();
		};
		//定义MV对象的属性
		var MV = function() {
			this.files = null;		//Music Visualize对象的文件
			this.fileName = null;	//Music Visualize对象的文件名
			this.ac = null;   		//Music Visualize对象的AudioContext
			this.status = 0;		//Music Visualize对象的状态（播放/停止状态）
			this.forceStop = false; 	//强制终止播放状态
			this.animationId = null;	//动画ID
			this.source = null;			//流媒体的源
		};
		
		function setWin () {
			var canvas = document.getElementById('drawCanvas');
			canvas.width = window.clientWidth
						   || document.documentElement.clientWidth
						   || document.body.clientWidth;
//			canvas.width -= 20;
			canvas.height = window.clientHeight
							|| document.documentElement.clientHeight
							|| document.body.clientHeight;
//			canvas.height -= 20;
			
		}
		
		//定义MV对象方法
		MV.prototype = {
			init: function() {
				//浏览器兼容设置
				window.AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext || window.msAudioContext;
				window.requestAnimationFrame = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.msRequestAnimationFrame;
				window.cancelAnimationFrame = window.cancelAnimationFrame || window.webkitCancelAnimationFrame || window.mozCancelAnimationFrame || window.msCancelAnimationFrame;
				try {
					this.ac = new AudioContext();
				} catch (err) {
					alert('!Your browser does not support AudioContext, Please see the console for more information!');
					console.log(err);
				};
					
				//add a eventListener for <inputfile id = uploader>
				var that = this,
					audioInput = document.getElementById("uploader");
				audioInput.onchange = function() {
					if (that.ac === null) {return;};	//new AudioContext失败，则退出函数
					//the if statement fixes the file selction cancle, because the onchange will trigger even the file selection been canceled
					if (audioInput.files.length !== 0) {
						//only process the first file
						that.files = audioInput.files[0];
						that.fileName = that.files.name;
						if (that.status === 1) {
							//the sound is still playing but we upload another file, so set the forceStop flag to true
							that.forceStop = true;
						};
						//document.getElementById('fileWrapper').style.opacity = 1;
						//that._updateInfo('Uploading', true);
						//once the file is ready,start the visualizer
						
						//console.log(that.fileName);
						that._read();
					};
				};
			},
			
			_read: function() {
				//read and decode the file into audio array buffer 
				var that = this,
					rfile = that.files,
					fr = new FileReader();
					
				fr.onload = function(e) {
					if (that.ac === null) {
                		return;
            		};
					that._updateInfo('Decoding the audio', true);
					//new AudioContext().decodeAudioData解码Audio文件，第一个参数为缓冲数列
					var fileResult = e.target.result;
					that.ac.decodeAudioData(fileResult, function(buffer) {
						that._updateInfo('Decode succussfully,start the visualizer', true);
						that._control(that.ac, buffer);	//转到播放和分析环节
					}, function(err) {
						alert('!Fail to decode the file');
						console.log(err);
					});
				};
				fr.onerror = function(err) {
	            	alert('!Fail to read the file');
	            	console.log(err);
		        };
		        //assign the file to the reader
        		that._updateInfo('Starting read the file', true);
        		fr.readAsArrayBuffer(rfile);		//ArrayBuffer方式读取
			},
			
			_control: function(audioContext, buffer) {
				var bufferSouceNode = audioContext.createBufferSource(),
					analyser = audioContext.createAnalyser(),
					that = this;
				
        		//connect the source to the analyser
        		bufferSouceNode.connect(analyser);
		        //connect the analyser to the destination(the speaker), or we won't hear the sound
		        analyser.connect(audioContext.destination);
		        bufferSouceNode.buffer = buffer;
		        
		        //play the source
		        if (!bufferSouceNode.start) {
		            bufferSouceNode.start = bufferSouceNode.noteOn //in old browsers use noteOn method
		            bufferSouceNode.stop = bufferSouceNode.noteOff //in old browsers use noteOn method
        		};
		        //stop the previous sound if any
		        if (this.animationId !== null) {
		            cancelAnimationFrame(this.animationId);
		        }
		        if (this.source !== null) {
		            this.source.stop(0);
		        }
		        bufferSouceNode.start(0);			//现代播放器都用这个播放
		        this.status = 1;
		        this.source = bufferSouceNode;
        		bufferSouceNode.onended = function() {
            		that._audioEnd(that);
        		};
        		this._updateInfo('Playing ' + this.fileName, false);
		        this._visualize_flow(analyser);
		        //this._visualize(analyser);
			},
			
			_visualize: function(analyser) {
				var that = this,
				canvas = document.getElementById('drawCanvas'),
			    cwidth = canvas.width,
			    cheight = canvas.height - 2,    //底部留一点余白
			    meterWidth = 10, //能量条的宽度
			    gap = 2, //能量条间的间距
			    capHeight = 2,
            	capStyle = '#fff',
			    meterNum = Math.round(cwidth / (meterWidth + gap)),	
			    capYPositionArray = [],		//store the vertical position of hte caps for the preivous frame
			    ctx = canvas.getContext('2d');
			    
				//定义一个渐变样式用于画图
				var gradient = ctx.createLinearGradient(0, 0, 0, cheight);
				gradient.addColorStop(1, '#0f0');
				gradient.addColorStop(0.5, '#ff0');
				gradient.addColorStop(0, '#f00');
				ctx.fillStyle = gradient;
				
				var drawMeter = function() {
			    	var array = new Uint8Array(analyser.frequencyBinCount);
			    	analyser.getByteFrequencyData(array);
			    	if (that.status === 0) {
		                //fix when some sounds end the value still not back to zero
		                for (var i = array.length - 1; i >= 0; i--) {
		                    array[i] = 0;
		                };
		                allCapsReachBottom = true;
		                for (var i = capYPositionArray.length - 1; i >= 0; i--) {
		                    allCapsReachBottom = allCapsReachBottom && (capYPositionArray[i] === 0);
		                };
		                if (allCapsReachBottom) {
		                    cancelAnimationFrame(that.animationId); //since the sound is top and animation finished, stop the requestAnimation to prevent potential memory leak,THIS IS VERY IMPORTANT!
		                    return;
		                };
	            	};
	            	var step = Math.round(array.length / meterNum); //sample limited data from the total array
            		ctx.clearRect(0, 0, cwidth, cheight);
			    	for (var i = 0; i < meterNum; i++) {
		                var value = array[i * step] * cheight / 256;
		                if (capYPositionArray.length < Math.round(meterNum)) {
		                    capYPositionArray.push(value);
		                };
		                ctx.fillStyle = capStyle;
		                //draw the cap, with transition effect
		                if (value < capYPositionArray[i]) {
		                    ctx.fillRect(i * (meterWidth + gap), cheight - (--capYPositionArray[i]), meterWidth, capHeight);
		                } else {
		                    ctx.fillRect(i * (meterWidth + gap), cheight - value, meterWidth, capHeight);
		                    capYPositionArray[i] = value;
		                };
		                ctx.fillStyle = gradient; //set the filllStyle to gradient for a better look
		                ctx.fillRect(i * (meterWidth + gap), cheight - value + capHeight, meterWidth, cheight); //the meter
		            }
			    	//这个与后面一句区别在this和that。严格模式下播放时this为undefined，一般模式下this指向window。
			    	//_visualize，_audioEnd这些为MV的方法，所以函数内部this指向MV，但其内部嵌套的函数并非MV的函数，其原型为window！
			    	//所以在进入嵌套函数内部时，this已经被改变了，所以才需要用一个that来保存this的指向对象MV
		            that.animationId = requestAnimationFrame(drawMeter); 
		        };
		        this.animationId = requestAnimationFrame(drawMeter);
			},
			
			_visualize_flow: function(analyser) {
				var that = this,
				canvas = document.getElementById('drawCanvas'),
			    cwidth = canvas.width,
			    cheight = canvas.height,
			    num = 50,		//能量球的数量
				sphere = [],	//能量球的半径应根据数量和画布大小而确定
			    ctx = canvas.getContext('2d');
			    
				var random = function (m, n) {
					return Math.round(Math.random()*(n - m) + m);
				};
				sphere = [];
				for (var i = 0; i < num; i++) {
					var x = random(0, cwidth),
						y = random(0, cheight),
						color = "rgba(" + random(0, 255) + "," + random(0, 255) + "," + random(0, 255) + ",0)";
					sphere.push({
						x: x,
						y: y,
						dy: 0.5 * Math.random() + 0.1,
						color: color
					});
				}
				
				var drawMeter = function() {
			    	var array = new Uint8Array(analyser.frequencyBinCount);
			    	analyser.getByteFrequencyData(array);
			    	var step = Math.round(array.length / num); //sample limited data from the total array
			    	ctx.clearRect(0, 0, cwidth, cheight);
			    	for (var n = 0; n < num; n++) {
			    		var r = 10 + Math.round(array[n * step] / 256 * (cwidth > cheight ? cwidth / 30 : cheight / 20));
			    		var s = sphere[n];
			    		var gradient = ctx.createRadialGradient(s.x, s.y, 0, s.x, s.y, r);
			    		gradient.addColorStop(0, "#fff");
			    		gradient.addColorStop(1, s.color);
			    		ctx.fillStyle = gradient;
			    		ctx.beginPath();
			    		ctx.arc(sphere[n].x, sphere[n].y, r, 0, Math.PI*2, true);
			    		s.y = s.y - 2 * s.dy;
			    		s.y = s.y <= 0 ? cheight : s.y;
			    		ctx.fill();
			    	}
			    	
			    	
				 	that.animationId = requestAnimationFrame(drawMeter); 
		        };
		        this.animationId = requestAnimationFrame(drawMeter);
			},
			
			_audioEnd: function(instance) {
		        if (this.forceStop) {
		            this.forceStop = false;
		            this.status = 1;
		            return;
		        };
		        this.status = 0;
		        var text = 'HTML5 Audio API showcase | An Audio Viusalizer';
		        document.getElementById('info').innerHTML = text;
		        document.getElementById('uploader').value = '';
		    },
		    
			_updateInfo: function(text, processing) {
		        var infoBar = document.getElementById('info'),
		            dots = '...',
		            i = 0,
		            that = this;
		        infoBar.innerHTML = text + dots.substring(0, i++);
		        if (this.infoUpdateId !== null) {
		            clearTimeout(this.infoUpdateId);
		        };
		        if (processing) {
		            //animate dots at the end of the info text
		            var animateDot = function() {
		                if (i > 3) {
		                    i = 0
		                };
		                infoBar.innerHTML = text + dots.substring(0, i++);
		                that.infoUpdateId = setTimeout(animateDot, 250);
		            }
		            this.infoUpdateId = setTimeout(animateDot, 250);
		        };
	    	}
		}
			
		</script>

	</body>

</html>